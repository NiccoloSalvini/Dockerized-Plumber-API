---
title: "Asynchronous API Scraping [Immobiliare.it](https://www.immobiliare.it/)"
output: 
  github_document:
    toc: TRUE
    toc_depth: 3
    fig_width: 5
    fig_height: 5
---

<!-- README.md is generated from README.Rmd. Please edit that file -->


```{r global.options, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,  
  strip.white = TRUE,                 # if FALSE knitr will not remove white spaces at the beg or end
  fig.path = "img/",                  # file path to the directory DESTINATION where knitr shall store the
  fig.width=12,                       # the width for plots created by code chunk
  fig.height=8,                       # the height for plots created by code chunk
  cache = FALSE                       # if TRUE knitr will cache the results to reuse in future knits
)


knitr::knit_hooks$set(imgcenter = function(before, options, envir){  # to center image 
  if (before) {                                                      # add imgcenter = TRUE
    htmltools::HTML("<p align='center'>")                            # to the chunk options
  } else {
    htmltools::HTML("</p>")
  }
})
```

x

<img src="img/logo.png" align="right" height="80" />
 
## API Infrastructure

[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity) <a href="https://www.buymeacoffee.com/gbraad" target="_blank"><img src="img/orange_img.png" alt="Buy Me A Coffee" style="height: 41px !important;width: 174px !important;box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;" ></a>


_author_: **[Niccol√≤ Salvini](https://niccolosalvini.netlify.app/)**
_date_: Last update: `r format(Sys.Date(), "%d %B, %Y")`


<br> 

 
This **RESTful API** provides a way to scrape the public [Immobiliare.it](https://www.immobiliare.it/) database of Real Estate rental market. Plumber does not have in-built features to handle calls to the endpoints **Asynchronously**, as a matter of fact this is handled inside the `plumber.R` MAIN function by the `foreach` package. Default options provides the Real Estate rental Milan zone, nonetheless it is possible to specify the city, the number of webpages of interest and also selling (instead of rental market). _A further recent improvement lets you specify the macrozone as filters directly in the api (in itinere)_ . For the time being is possible to filter out through immobiliare the macrozone and the provide the API the url.

API is built with the `Plumber` framework, moreover it is containerized with Docker. _It will be hosted on AWS EC2 server/ GCP with scheduler. _
On top of that each day a scheduler runs scraping functions and _store daily data on a DB that can be queried given credentials_ (in itinere):

<br><br>



minimal reprex why `foreach` handles requests faster vs `furrr` (`future` spin-off). On x axis the number of urls processed, on y axis run time:

```{r furrr, echo=FALSE, imgcenter = TRUE, fig.cap="linear time big-O(n)"}
knitr::include_graphics("img/run_timefurrr.png") 
```

```{r foreach, echo=FALSE, imgcenter = TRUE, fig.cap="log time  big-O(log(n))"}
knitr::include_graphics("img/run_timeforeach.png") 
```


## API Documentation:  

- Get FAST data, it covers 5 covariates: title, price, num of rooms, sqmeter, primarykey
```r
      GET */scrape

      @param city [chr string] the city you are interested in (e.g. "roma", "milano", "firenze"--> lowercase, without accent)
      @param npages [positive integer] number of pages to scrape, default = 10, min  = 2, max = 300
      @param type [chr string] "affitto" = rents, "vendita"  = sell 
      content-type: application/json 
```
- Get all the links 

```r
      GET */link

      @param city [chr string] the city you are interested to extract data (lowercase without accent)
      @param npages [positive integer] number of pages to scrape default = 10, min  = 2, max = 300
      @param type [chr string] "affitto" = rents, "vendita"  = sell 
      @param .thesis [logical] data used for master thesis
      content-type: application/json 
```   
      
-  Get the complete set of covariates (52) from each single links, takes a while

```r
      GET */complete

      @param city [chr string] the city you are interested to extract data (lowercase without accent)
      @param npages [positive integer] number of pages to scrape default = 10, min  = 2, max = 300
      @param type [chr string] "affitto" = rents, "vendita"  = sell 
      @param .thesis [logical] data used for master thesis
      content-type: application/json
            

```

 