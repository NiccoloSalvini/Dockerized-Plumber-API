---
title: "Asynchronous API Scraping [Immobiliare.it](https://www.immobiliare.it/)"
output: 
  github_document:
    toc: TRUE
    toc_depth: 3
    fig_width: 5
    fig_height: 5
---

<!-- README.md is generated from README.Rmd. Please edit that file -->


```{r global.options, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,  
  strip.white = TRUE,                 # if FALSE knitr will not remove white spaces at the beg or end
  fig.path = "img/",                  # file path to the directory DESTINATION where knitr shall store the
  fig.width=12,                       # the width for plots created by code chunk
  fig.height=8,                       # the height for plots created by code chunk
  cache = FALSE                       # if TRUE knitr will cache the results to reuse in future knits
)


knitr::knit_hooks$set(imgcenter = function(before, options, envir){  # to center image 
  if (before) {                                                      # add imgcenter = TRUE
    htmltools::HTML("<p align='center'>")                            # to the chunk options
  } else {
    htmltools::HTML("</p>")
  }
})
```

x

<img src="img/logo.png" align="right" height="80" />
 
## API Infrastructure

[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity) <a href="https://www.buymeacoffee.com/gbraad" target="_blank"><img src="img/orange_img.png" alt="Buy Me A Coffee" style="height: 41px !important;width: 174px !important;box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;" ></a>


_author_: **[Niccol√≤ Salvini](https://niccolosalvini.netlify.app/)**
_date_: Last update: `r format(Sys.Date(), "%d %B, %Y")`


<br> 

 
This **RESTful API** provides a way to scrape the public [Immobiliare.it](https://www.immobiliare.it/) database of Real Estate rental market. Plumber does not have in-built features to handle calls to the endpoints **Asynchronously**, as a matter of fact this is handled inside the `plumber.R` MAIN function by the `foreach` package. Default options provides to the scraping functions the Real Estate market Milan url, (it will be possible for sure to provide only the city information in the very next future). It can be extended also for other cities by providing different urls. API are built with `Plumber` api framework. They are containerized with Docker. It will be hosted on AWS EC2 server/ GCP with scheduler. 
On top of that each day a scheduler runs scraping functions and _store daily data on a DB that can be queried given credentials_ (in itinere):

<br><br>



minimal reprex why `foreach` handles requests faster vs `furrr` (`future` spin-off). On x axis the number of urls processed, on y axis run time:

```{r furrr, echo=FALSE, imgcenter = TRUE, fig.cap="linear time big-O(n)"}
knitr::include_graphics("img/run_timefurrr.png") 
```

```{r foreach, echo=FALSE, imgcenter = TRUE, fig.cap="log time  big-O(log(n))"}
knitr::include_graphics("img/run_timeforeach.png") 
```


## API Documentation:  

- Get FAST data, it covers 5 covariates: title, price, num of rooms, sqmeter, primarykey
```r
      GET */scrape

      param url [url string] the link from which you are interested to extract data 
      param npages [positive integer] number of pages to scrape (1-300) 
      content-type: application/json 
```
- Get all the links 

```r
      GET */link

      param url [url string]  the link from which you are interested to extract data
      param npages  [positive integer] number of pages to scrape (1-300) 
      content-type: application/json 
```   
      
-  Get the complete set of covariates (52) from each single links, takes a while

```r
      GET */complete

      param url  _url string_ url the link from which you are interested to extract data
      param npages [positive integer] number of pages to scrape (1-300) 
      content-type: application/json
            

```

 